// Code generated by fastssz. DO NOT EDIT.
// Hash: e201af246edc321558124ddc9597db8fe1eb32874124c0f9956e8d4b30b2990d
// Version: 0.1.3
package verkle

import (
	ssz "github.com/ferranbt/fastssz"
)

// MarshalSSZ ssz marshals the IPAProof object
func (i *IPAProof) MarshalSSZ() ([]byte, error) {
	return ssz.MarshalSSZ(i)
}

// MarshalSSZTo ssz marshals the IPAProof object to a target array
func (i *IPAProof) MarshalSSZTo(buf []byte) (dst []byte, err error) {
	dst = buf

	// Field (0) 'CL'
	for ii := 0; ii < 8; ii++ {
		dst = append(dst, i.CL[ii][:]...)
	}

	// Field (1) 'CR'
	for ii := 0; ii < 8; ii++ {
		dst = append(dst, i.CR[ii][:]...)
	}

	// Field (2) 'FinalEvaluation'
	dst = append(dst, i.FinalEvaluation[:]...)

	return
}

// UnmarshalSSZ ssz unmarshals the IPAProof object
func (i *IPAProof) UnmarshalSSZ(buf []byte) error {
	var err error
	size := uint64(len(buf))
	if size != 544 {
		return ssz.ErrSize
	}

	// Field (0) 'CL'

	for ii := 0; ii < 8; ii++ {
		copy(i.CL[ii][:], buf[0:256][ii*32:(ii+1)*32])
	}

	// Field (1) 'CR'

	for ii := 0; ii < 8; ii++ {
		copy(i.CR[ii][:], buf[256:512][ii*32:(ii+1)*32])
	}

	// Field (2) 'FinalEvaluation'
	copy(i.FinalEvaluation[:], buf[512:544])

	return err
}

// SizeSSZ returns the ssz encoded size in bytes for the IPAProof object
func (i *IPAProof) SizeSSZ() (size int) {
	size = 544
	return
}

// HashTreeRoot ssz hashes the IPAProof object
func (i *IPAProof) HashTreeRoot() ([32]byte, error) {
	return ssz.HashWithDefaultHasher(i)
}

// HashTreeRootWith ssz hashes the IPAProof object with a hasher
func (i *IPAProof) HashTreeRootWith(hh ssz.HashWalker) (err error) {
	indx := hh.Index()

	// Field (0) 'CL'
	{
		subIndx := hh.Index()
		for _, i := range i.CL {
			hh.Append(i[:])
		}
		hh.Merkleize(subIndx)
	}

	// Field (1) 'CR'
	{
		subIndx := hh.Index()
		for _, i := range i.CR {
			hh.Append(i[:])
		}
		hh.Merkleize(subIndx)
	}

	// Field (2) 'FinalEvaluation'
	hh.PutBytes(i.FinalEvaluation[:])

	hh.Merkleize(indx)
	return
}

// GetTree ssz hashes the IPAProof object
func (i *IPAProof) GetTree() (*ssz.Node, error) {
	return ssz.ProofTree(i)
}

// MarshalSSZ ssz marshals the VerkleProof object
func (v *VerkleProof) MarshalSSZ() ([]byte, error) {
	return ssz.MarshalSSZ(v)
}

// MarshalSSZTo ssz marshals the VerkleProof object to a target array
func (v *VerkleProof) MarshalSSZTo(buf []byte) (dst []byte, err error) {
	dst = buf
	offset := int(588)

	// Offset (0) 'OtherStems'
	dst = ssz.WriteOffset(dst, offset)
	for ii := 0; ii < len(v.OtherStems); ii++ {
		offset += 4
		offset += len(v.OtherStems[ii])
	}

	// Offset (1) 'DepthExtensionPresent'
	dst = ssz.WriteOffset(dst, offset)
	offset += len(v.DepthExtensionPresent)

	// Offset (2) 'CommitmentsByPath'
	dst = ssz.WriteOffset(dst, offset)
	for ii := 0; ii < len(v.CommitmentsByPath); ii++ {
		offset += 4
		offset += len(v.CommitmentsByPath[ii])
	}

	// Field (3) 'D'
	dst = append(dst, v.D[:]...)

	// Field (4) 'IPAProof'
	if v.IPAProof == nil {
		v.IPAProof = new(IPAProof)
	}
	if dst, err = v.IPAProof.MarshalSSZTo(dst); err != nil {
		return
	}

	// Field (0) 'OtherStems'
	if size := len(v.OtherStems); size > 65536 {
		err = ssz.ErrListTooBigFn("VerkleProof.OtherStems", size, 65536)
		return
	}
	{
		offset = 4 * len(v.OtherStems)
		for ii := 0; ii < len(v.OtherStems); ii++ {
			dst = ssz.WriteOffset(dst, offset)
			offset += len(v.OtherStems[ii])
		}
	}
	for ii := 0; ii < len(v.OtherStems); ii++ {
		if size := len(v.OtherStems[ii]); size > 31 {
			err = ssz.ErrBytesLengthFn("VerkleProof.OtherStems[ii]", size, 31)
			return
		}
		dst = append(dst, v.OtherStems[ii]...)
	}

	// Field (1) 'DepthExtensionPresent'
	if size := len(v.DepthExtensionPresent); size > 65536 {
		err = ssz.ErrBytesLengthFn("VerkleProof.DepthExtensionPresent", size, 65536)
		return
	}
	dst = append(dst, v.DepthExtensionPresent...)

	// Field (2) 'CommitmentsByPath'
	if size := len(v.CommitmentsByPath); size > 65536 {
		err = ssz.ErrListTooBigFn("VerkleProof.CommitmentsByPath", size, 65536)
		return
	}
	{
		offset = 4 * len(v.CommitmentsByPath)
		for ii := 0; ii < len(v.CommitmentsByPath); ii++ {
			dst = ssz.WriteOffset(dst, offset)
			offset += len(v.CommitmentsByPath[ii])
		}
	}
	for ii := 0; ii < len(v.CommitmentsByPath); ii++ {
		if size := len(v.CommitmentsByPath[ii]); size > 32 {
			err = ssz.ErrBytesLengthFn("VerkleProof.CommitmentsByPath[ii]", size, 32)
			return
		}
		dst = append(dst, v.CommitmentsByPath[ii]...)
	}

	return
}

// UnmarshalSSZ ssz unmarshals the VerkleProof object
func (v *VerkleProof) UnmarshalSSZ(buf []byte) error {
	var err error
	size := uint64(len(buf))
	if size < 588 {
		return ssz.ErrSize
	}

	tail := buf
	var o0, o1, o2 uint64

	// Offset (0) 'OtherStems'
	if o0 = ssz.ReadOffset(buf[0:4]); o0 > size {
		return ssz.ErrOffset
	}

	if o0 < 588 {
		return ssz.ErrInvalidVariableOffset
	}

	// Offset (1) 'DepthExtensionPresent'
	if o1 = ssz.ReadOffset(buf[4:8]); o1 > size || o0 > o1 {
		return ssz.ErrOffset
	}

	// Offset (2) 'CommitmentsByPath'
	if o2 = ssz.ReadOffset(buf[8:12]); o2 > size || o1 > o2 {
		return ssz.ErrOffset
	}

	// Field (3) 'D'
	copy(v.D[:], buf[12:44])

	// Field (4) 'IPAProof'
	if v.IPAProof == nil {
		v.IPAProof = new(IPAProof)
	}
	if err = v.IPAProof.UnmarshalSSZ(buf[44:588]); err != nil {
		return err
	}

	// Field (0) 'OtherStems'
	{
		buf = tail[o0:o1]
		num, err := ssz.DecodeDynamicLength(buf, 65536)
		if err != nil {
			return err
		}
		v.OtherStems = make([][]byte, num)
		err = ssz.UnmarshalDynamic(buf, num, func(indx int, buf []byte) (err error) {
			if len(buf) > 31 {
				return ssz.ErrBytesLength
			}
			if cap(v.OtherStems[indx]) == 0 {
				v.OtherStems[indx] = make([]byte, 0, len(buf))
			}
			v.OtherStems[indx] = append(v.OtherStems[indx], buf...)
			return nil
		})
		if err != nil {
			return err
		}
	}

	// Field (1) 'DepthExtensionPresent'
	{
		buf = tail[o1:o2]
		if len(buf) > 65536 {
			return ssz.ErrBytesLength
		}
		if cap(v.DepthExtensionPresent) == 0 {
			v.DepthExtensionPresent = make([]byte, 0, len(buf))
		}
		v.DepthExtensionPresent = append(v.DepthExtensionPresent, buf...)
	}

	// Field (2) 'CommitmentsByPath'
	{
		buf = tail[o2:]
		num, err := ssz.DecodeDynamicLength(buf, 65536)
		if err != nil {
			return err
		}
		v.CommitmentsByPath = make([][]byte, num)
		err = ssz.UnmarshalDynamic(buf, num, func(indx int, buf []byte) (err error) {
			if len(buf) > 32 {
				return ssz.ErrBytesLength
			}
			if cap(v.CommitmentsByPath[indx]) == 0 {
				v.CommitmentsByPath[indx] = make([]byte, 0, len(buf))
			}
			v.CommitmentsByPath[indx] = append(v.CommitmentsByPath[indx], buf...)
			return nil
		})
		if err != nil {
			return err
		}
	}
	return err
}

// SizeSSZ returns the ssz encoded size in bytes for the VerkleProof object
func (v *VerkleProof) SizeSSZ() (size int) {
	size = 588

	// Field (0) 'OtherStems'
	for ii := 0; ii < len(v.OtherStems); ii++ {
		size += 4
		size += len(v.OtherStems[ii])
	}

	// Field (1) 'DepthExtensionPresent'
	size += len(v.DepthExtensionPresent)

	// Field (2) 'CommitmentsByPath'
	for ii := 0; ii < len(v.CommitmentsByPath); ii++ {
		size += 4
		size += len(v.CommitmentsByPath[ii])
	}

	return
}

// HashTreeRoot ssz hashes the VerkleProof object
func (v *VerkleProof) HashTreeRoot() ([32]byte, error) {
	return ssz.HashWithDefaultHasher(v)
}

// HashTreeRootWith ssz hashes the VerkleProof object with a hasher
func (v *VerkleProof) HashTreeRootWith(hh ssz.HashWalker) (err error) {
	indx := hh.Index()

	// Field (0) 'OtherStems'
	{
		subIndx := hh.Index()
		num := uint64(len(v.OtherStems))
		if num > 65536 {
			err = ssz.ErrIncorrectListSize
			return
		}
		for _, elem := range v.OtherStems {
			{
				elemIndx := hh.Index()
				byteLen := uint64(len(elem))
				if byteLen > 31 {
					err = ssz.ErrIncorrectListSize
					return
				}
				hh.AppendBytes32(elem)
				hh.MerkleizeWithMixin(elemIndx, byteLen, (31+31)/32)
			}
		}
		hh.MerkleizeWithMixin(subIndx, num, 65536)
	}

	// Field (1) 'DepthExtensionPresent'
	{
		elemIndx := hh.Index()
		byteLen := uint64(len(v.DepthExtensionPresent))
		if byteLen > 65536 {
			err = ssz.ErrIncorrectListSize
			return
		}
		hh.Append(v.DepthExtensionPresent)
		hh.MerkleizeWithMixin(elemIndx, byteLen, (65536+31)/32)
	}

	// Field (2) 'CommitmentsByPath'
	{
		subIndx := hh.Index()
		num := uint64(len(v.CommitmentsByPath))
		if num > 65536 {
			err = ssz.ErrIncorrectListSize
			return
		}
		for _, elem := range v.CommitmentsByPath {
			{
				elemIndx := hh.Index()
				byteLen := uint64(len(elem))
				if byteLen > 32 {
					err = ssz.ErrIncorrectListSize
					return
				}
				hh.AppendBytes32(elem)
				hh.MerkleizeWithMixin(elemIndx, byteLen, (32+31)/32)
			}
		}
		hh.MerkleizeWithMixin(subIndx, num, 65536)
	}

	// Field (3) 'D'
	hh.PutBytes(v.D[:])

	// Field (4) 'IPAProof'
	if v.IPAProof == nil {
		v.IPAProof = new(IPAProof)
	}
	if err = v.IPAProof.HashTreeRootWith(hh); err != nil {
		return
	}

	hh.Merkleize(indx)
	return
}

// GetTree ssz hashes the VerkleProof object
func (v *VerkleProof) GetTree() (*ssz.Node, error) {
	return ssz.ProofTree(v)
}

// MarshalSSZ ssz marshals the SuffixStateDiff object
func (s *SuffixStateDiff) MarshalSSZ() ([]byte, error) {
	return ssz.MarshalSSZ(s)
}

// MarshalSSZTo ssz marshals the SuffixStateDiff object to a target array
func (s *SuffixStateDiff) MarshalSSZTo(buf []byte) (dst []byte, err error) {
	dst = buf

	// Field (0) 'Suffix'
	dst = ssz.MarshalUint8(dst, s.Suffix)

	// Field (1) 'CurrentValue'
	if size := len(s.CurrentValue); size != 32 {
		err = ssz.ErrBytesLengthFn("SuffixStateDiff.CurrentValue", size, 32)
		return
	}
	dst = append(dst, s.CurrentValue...)

	// Field (2) 'NewValue'
	if size := len(s.NewValue); size != 32 {
		err = ssz.ErrBytesLengthFn("SuffixStateDiff.NewValue", size, 32)
		return
	}
	dst = append(dst, s.NewValue...)

	return
}

// UnmarshalSSZ ssz unmarshals the SuffixStateDiff object
func (s *SuffixStateDiff) UnmarshalSSZ(buf []byte) error {
	var err error
	size := uint64(len(buf))
	if size != 65 {
		return ssz.ErrSize
	}

	// Field (0) 'Suffix'
	s.Suffix = ssz.UnmarshallUint8(buf[0:1])

	// Field (1) 'CurrentValue'
	if cap(s.CurrentValue) == 0 {
		s.CurrentValue = make([]byte, 0, len(buf[1:33]))
	}
	s.CurrentValue = append(s.CurrentValue, buf[1:33]...)

	// Field (2) 'NewValue'
	if cap(s.NewValue) == 0 {
		s.NewValue = make([]byte, 0, len(buf[33:65]))
	}
	s.NewValue = append(s.NewValue, buf[33:65]...)

	return err
}

// SizeSSZ returns the ssz encoded size in bytes for the SuffixStateDiff object
func (s *SuffixStateDiff) SizeSSZ() (size int) {
	size = 65
	return
}

// HashTreeRoot ssz hashes the SuffixStateDiff object
func (s *SuffixStateDiff) HashTreeRoot() ([32]byte, error) {
	return ssz.HashWithDefaultHasher(s)
}

// HashTreeRootWith ssz hashes the SuffixStateDiff object with a hasher
func (s *SuffixStateDiff) HashTreeRootWith(hh ssz.HashWalker) (err error) {
	indx := hh.Index()

	// Field (0) 'Suffix'
	hh.PutUint8(s.Suffix)

	// Field (1) 'CurrentValue'
	if size := len(s.CurrentValue); size != 32 {
		err = ssz.ErrBytesLengthFn("SuffixStateDiff.CurrentValue", size, 32)
		return
	}
	hh.PutBytes(s.CurrentValue)

	// Field (2) 'NewValue'
	if size := len(s.NewValue); size != 32 {
		err = ssz.ErrBytesLengthFn("SuffixStateDiff.NewValue", size, 32)
		return
	}
	hh.PutBytes(s.NewValue)

	hh.Merkleize(indx)
	return
}

// GetTree ssz hashes the SuffixStateDiff object
func (s *SuffixStateDiff) GetTree() (*ssz.Node, error) {
	return ssz.ProofTree(s)
}

// MarshalSSZ ssz marshals the StemStateDiff object
func (s *StemStateDiff) MarshalSSZ() ([]byte, error) {
	return ssz.MarshalSSZ(s)
}

// MarshalSSZTo ssz marshals the StemStateDiff object to a target array
func (s *StemStateDiff) MarshalSSZTo(buf []byte) (dst []byte, err error) {
	dst = buf
	offset := int(35)

	// Field (0) 'Stem'
	dst = append(dst, s.Stem[:]...)

	// Offset (1) 'SuffixDiffs'
	dst = ssz.WriteOffset(dst, offset)
	offset += len(s.SuffixDiffs) * 65

	// Field (1) 'SuffixDiffs'
	if size := len(s.SuffixDiffs); size > 1073741824 {
		err = ssz.ErrListTooBigFn("StemStateDiff.SuffixDiffs", size, 1073741824)
		return
	}
	for ii := 0; ii < len(s.SuffixDiffs); ii++ {
		if dst, err = s.SuffixDiffs[ii].MarshalSSZTo(dst); err != nil {
			return
		}
	}

	return
}

// UnmarshalSSZ ssz unmarshals the StemStateDiff object
func (s *StemStateDiff) UnmarshalSSZ(buf []byte) error {
	var err error
	size := uint64(len(buf))
	if size < 35 {
		return ssz.ErrSize
	}

	tail := buf
	var o1 uint64

	// Field (0) 'Stem'
	copy(s.Stem[:], buf[0:31])

	// Offset (1) 'SuffixDiffs'
	if o1 = ssz.ReadOffset(buf[31:35]); o1 > size {
		return ssz.ErrOffset
	}

	if o1 < 35 {
		return ssz.ErrInvalidVariableOffset
	}

	// Field (1) 'SuffixDiffs'
	{
		buf = tail[o1:]
		num, err := ssz.DivideInt2(len(buf), 65, 1073741824)
		if err != nil {
			return err
		}
		s.SuffixDiffs = make([]*SuffixStateDiff, num)
		for ii := 0; ii < num; ii++ {
			if err = s.SuffixDiffs[ii].UnmarshalSSZ(buf[ii*65 : (ii+1)*65]); err != nil {
				return err
			}
		}
	}
	return err
}

// SizeSSZ returns the ssz encoded size in bytes for the StemStateDiff object
func (s *StemStateDiff) SizeSSZ() (size int) {
	size = 35

	// Field (1) 'SuffixDiffs'
	size += len(s.SuffixDiffs) * 65

	return
}

// HashTreeRoot ssz hashes the StemStateDiff object
func (s *StemStateDiff) HashTreeRoot() ([32]byte, error) {
	return ssz.HashWithDefaultHasher(s)
}

// HashTreeRootWith ssz hashes the StemStateDiff object with a hasher
func (s *StemStateDiff) HashTreeRootWith(hh ssz.HashWalker) (err error) {
	indx := hh.Index()

	// Field (0) 'Stem'
	hh.PutBytes(s.Stem[:])

	// Field (1) 'SuffixDiffs'
	{
		subIndx := hh.Index()
		num := uint64(len(s.SuffixDiffs))
		if num > 1073741824 {
			err = ssz.ErrIncorrectListSize
			return
		}
		for _, elem := range s.SuffixDiffs {
			if err = elem.HashTreeRootWith(hh); err != nil {
				return
			}
		}
		hh.MerkleizeWithMixin(subIndx, num, 1073741824)
	}

	hh.Merkleize(indx)
	return
}

// GetTree ssz hashes the StemStateDiff object
func (s *StemStateDiff) GetTree() (*ssz.Node, error) {
	return ssz.ProofTree(s)
}
